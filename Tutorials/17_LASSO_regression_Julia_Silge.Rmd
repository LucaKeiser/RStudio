---
title: "LASSO Regression in R"
author: "Luca"
date: '2022-06-07'
output: html_document
---


Check out the full tutorial by Julia Silge [here](https://juliasilge.com/blog/lasso-the-office/)


### load packages

```{r}
library(tidyverse)
library(tidymodels)
library(tidylog)
library(vip)
library(schrute)

theme_set(theme_light())

# schrute needs to be installed in order to get all the data
# install.packages("schrute")
```



### get the data

```{r}
ratings_raw <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-03-17/office_ratings.csv")

ratings_raw
skimr::skim(ratings_raw)


office_raw <- schrute::theoffice

office_raw
skimr::skim(office_raw)
```

### prepare data for joining

The episode numbers and titles are not consistent between the two data sets, so we can use regular expressions to do a better job of matching the datasets up for joining.

```{r}
# take a look at the differences
waldo::compare(unique(ratings_raw$title), unique(office_raw$episode_name))

ratings_raw %>% 
  group_by(season, episode) %>% 
  count(title) %>% 
  select(-n)

office_raw %>% 
  group_by(season, episode) %>% 
  count(episode_name) %>% 
  select(-n)


# prepare for joining by episode_name

# 1.
# create regex expression to sync the titles
remove_regex <- "[:punct:]|[:digit:]|parts |part |the | and"

office_ratings <- ratings_raw %>% 
  mutate(
    episode_name = str_to_lower(title),
    episode_name = str_remove_all(episode_name, remove_regex),
    episode_name = str_trim(episode_name)
  ) %>% 
  select(episode_name, imdb_rating)

office_ratings

# 2.
office_info <- office_raw %>% 
  mutate(
    season = as.numeric(season),
    episode = as.numeric(episode),
    episode_name = str_to_lower(episode_name),
    episode_name = str_remove_all(episode_name, remove_regex),
    episode_name = str_replace_all(episode_name, "boys  girls", "boys girls"),
    episode_name = str_replace_all(episode_name, "email surveilance", "email surveillance"),
    episode_name = str_replace_all(episode_name, "sx ed", "sex ed"),
    episode_name = str_replace_all(episode_name, "cover", "coverup"),
    episode_name = str_trim(episode_name)
  ) %>% 
  select(season, episode, episode_name,
         director, writer, character)

office_info

# did we mange to sync all?
office_ratings %>% 
  distinct(episode_name) %>% 
  anti_join(office_info %>% 
              distinct(episode_name))
# yes!
```


## Building data sets for modeling

### how many times does a character speak per episode?
we created some sort of one/hot-encoding here

```{r}
characters <- office_info %>%
  
  # how many lines per episode?
  count(episode_name, character) %>%
  
  # how many lines overall?
  add_count(character, 
            wt = n, 
            name = "character_count") %>% 
  # we just want to keep those characters, which hat at least 800 lines overall 
  filter(character_count > 800) %>% 
  select(-character_count) %>% 
  pivot_wider(
    names_from = character,
    values_from = n,
    values_fill = list(n = 0)
  )

# Andy has no lines in the episode alliance but 44 in aarm for example
characters
```
for every episode we have the character and the amount lines s/he speaks



### which directors and writers are involved in each episode?
we created some sort of one/hot-encoding here

```{r}
creators <- office_info %>% 
  distinct(episode_name, director, writer) %>% 
  
  # create long format first and do some cleaning
  pivot_longer(
    cols = c(director, writer), 
    names_to = "role",
    values_to = "person"
  ) %>% 
  separate_rows(person, sep = ";") %>% 
  add_count(person) %>% 
  filter(n > 10) %>% 
  distinct(episode_name, person) %>% 
  mutate(person_value = 1) %>% 
  
  # create a wide format for modeling
  pivot_wider(
    names_from = person,
    values_from = person_value,
    values_fill = list(person_value = 0)
  )


creators

creators %>% 
  select(-episode_name) %>% 
  summarise_all(.funs = sum) %>% 
  View()
```




### Create data set for modeling
Next, let’s find the season and episode number for each episode, and then finally let’s put it all together into one dataset for modeling.

```{r}
office <- office_info %>% 
  distinct(season, episode, episode_name) %>% 
  inner_join(characters) %>% 
  inner_join(creators) %>% 
  inner_join(office_ratings %>% 
               select(episode_name, imdb_rating)) %>% 
  janitor::clean_names()

office
```

now we have a data set with all the information (season, episode, episode_name, chracters and creators)



### let's take a look (a bit of EDA)

```{r}
office %>% 
  group_by(season) %>% 
  summarise(avg_rating = mean(imdb_rating)) %>% 
  ggplot(aes(as.factor(season), avg_rating,
             fill = as.factor(season))) +
  geom_col(show.legend = FALSE)

office %>% 
  ggplot(aes(episode, imdb_rating,
             fill = as.factor(episode))) + 
  geom_boxplot(show.legend = FALSE)
```

Ratings are higher for episodes later in the season. What else is associated with higher ratings? Let’s use lasso regression to find out.



## train a model

### initial split, training and testing set

```{r}
set.seed(1234)

office_split <- initial_split(office,
                              strata = season)

office_train <- training(office_split)
office_test <- testing(office_split)
```


### create recipe

```{r}
office_rec <- recipe(imdb_rating ~ ., data = office_train) %>% 
  
  # Next, we update the role for episode_name, since this is a variable we 
  # might like to keep around for convenience as an identifier for rows 
  # but is not a predictor or outcome.
  # So we have a variable in our data set which we do not want to use
  # as a predictor but we would like to keep it => update_role!
  update_role(episode_name, new_role = "ID") %>% 
  
  # remove variables that contain only a single value (zero variance filter)
  step_zv(all_numeric_predictors()) %>% 
  
  # center and scale => needed to run lasso regression efficiently
  step_normalize(all_numeric_predictors())

# take a look at the recipe
office_rec %>% 
  prep()

# take a look at the data
office_baked <- office_rec %>% 
  prep(training = office_train,
       strings_as_factors = FALSE) %>% 
  bake(new_data = office_train)

skimr::skim(office_baked)
```


### specify and fit the model

Now it’s time to specify and then fit our models
=> set up one model specification for lasso regression
NOTE: I picked a value for penalty (sort of randomly) and I set mixture = 1 for lasso. I am using a workflow() in this example for convenience; these are objects that can help you manage modeling pipelines more easily, with pieces that fit together like Lego blocks. You can fit() a workflow, much like you can fit a model, and then you can pull out the fit object and tidy() it!

```{r}
LASSO_spec <- linear_reg() %>% 
  set_engine("glmnet") %>% 
  set_mode("regression") %>% 
  set_args(penalty = 0.1,
           # for LASSO regression
           mixture = 1)


LASSO_wf <- workflow() %>% 
  add_recipe(office_rec)


LASSO_fit <- LASSO_wf %>% 
  add_model(LASSO_spec) %>% 
  fit(data = office_train)

# NOTE: LASSO_fit is still a workflow-object!
class(LASSO_fit)

# extract what we want
LASSO_fit %>% 
  extract_fit_parsnip() %>%
  tidy() %>% 
  arrange(desc(estimate))
# we can see what contributes to higher IMDB ratings
```



### tune LASSO parameters

Let's build a set of resamples

```{r}
# always set a seed
set.seed(1234)

office_boot <- bootstraps(office_train,
                          strata = season,
                          times = 25)

office_boot

# what happens in the background?
office_boot$splits[[1]] %>% 
  tidy() %>% 
  group_by(Data) %>% 
  slice_head(n = 10)
```

create regular grid for tuning

```{r}
# specify tune
LASSO_tune <- linear_reg() %>% 
  set_engine("glmnet") %>% 
  set_mode("regression") %>%
  
  # set penalty = tune()
  set_args(penalty = tune(),
           mixture = 1)

# alsways set seed
set.seed(1234)
lambda_grid <- grid_regular(penalty(), 
                            levels = 50)
```

train the model on the bootsrapped resamples

```{r}
system.time(
  set.seed(2020),
  LASSO_grid <- tune_grid(
    LASSO_wf %>% add_model(LASSO_tune),
    resamples = office_boot,
    grid = lambda_grid
    
  )
)

LASSO_grid
```


collect metrics

```{r}
LASSO_grid %>%
  collect_metrics()

# ggplot2
LASSO_grid %>% 
  collect_metrics() %>% 
  ggplot(aes(penalty, mean,
             color = .metric)) + 
  geom_errorbar(aes(ymin = mean - std_err ,
                    ymax = mean + std_err ),
                alpha = 0.5) + 
  geom_line(size = 1.5) + 
  facet_wrap(~ .metric, 
             scales = "free",
             nrow = 2) + 
  scale_x_log10() + 
  theme(legend.position = "none")

# autoplot
autoplot(LASSO_grid)
```


### finalize

```{r}
LASSO_grid %>%
  collect_metrics() %>% 
  filter(.metric == "rmse") %>% 
  arrange(mean)

LASSO_grid %>% 
  show_best("rmse")

# select the model with the lowest rmse
lowest_rmse <- LASSO_grid %>% 
  select_best("rmse")

# let's finalize the workflow
LASSO_final_wf <- LASSO_wf %>% 
  add_model(LASSO_tune) %>% 
  finalize_workflow(lowest_rmse)

# take a look
LASSO_final_wf

# fit the final and take a look at variable importance
LASSO_final_wf %>% 
  fit(office_train) %>% 
  extract_fit_engine() %>% 
  vi(lambda = lowest_rmse$penalty) %>%
  mutate(Importance = abs(Importance),
         Variable = fct_reorder(Variable, Importance)) %>% 
  ggplot(aes(x = Importance, y = Variable, fill = Sign)) +
  geom_col() +
  scale_x_continuous(expand = c(0, 0)) +
  labs(y = NULL)
```

something is up here. I get two very different results than Julia...


# now we can return to our test data

And then, finally, let’s return to our test data. The tune package has a function last_fit() which is nice for situations when you have tuned and finalized a model or workflow and want to fit it one last time on your training data and evaluate it on your testing data. You only have to pass this function your finalized model/workflow and your split.

```{r}
LASSO_final_wf %>% 
  last_fit(office_split) %>% 
  collect_metrics()
```

