---
title: "Predicting NYC Airbnb Prices"
author: "Luca"
date: "15/07/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(tidymodels)
library(textrecipes)
library(scales)
library(stacks)

theme_set(theme_light())
```

Set up parallel processing
```{r}
library(doParallel)

n_cores <- detectCores() - 1 # -1 to prevent RStudio from crashing...
registerDoParallel(cores = n_cores)
```

Get the data
```{r}
dataset <- read_csv("C:/Users/LucaK/Desktop/GitHub/RStudio/Datasets/Airbnb/train.csv") %>% 
  mutate(price = log(price + 1))                              # transforming the price => more symmetric distribution
holdout <- read_csv("C:/Users/LucaK/Desktop/GitHub/RStudio/Datasets/Airbnb/test.csv")

set.seed(2021)

spl <- initial_split(dataset, 0.75)
train <- training(spl)
test <- testing(spl)
```

Take a look
```{r}
train %>% 
  count(name, sort = TRUE)


train %>% 
  ggplot(aes(price)) + 
  geom_histogram()
```

create first summarizing function
```{r}
summarize_prices <- function(tbl) {
  tbl %>% 
    summarize(avg_price = exp(mean(price) - 1),
              median_price = exp(median(price) - 1),
              n = n()) %>% 
    arrange(desc(n))
}
```

```{r}
train %>% 
  summarize_prices()
```

first visualisations (looking for variation in the data)
```{r}
train %>% 
  group_by(neighbourhood_group) %>% 
  summarize_prices() %>% 
  mutate(neighbourhood_group = fct_reorder(neighbourhood_group, median_price)) %>% 
  ggplot(aes(median_price, neighbourhood_group)) + 
  geom_col()

train %>% 
  mutate(neighbourhood_group = fct_reorder(neighbourhood_group, price)) %>% 
  ggplot(aes(exp(price), neighbourhood_group)) + 
  geom_boxplot() + 
  scale_x_log10()

train %>% 
  mutate(neighbourhood = fct_lump(neighbourhood, 40),    # too many neighbourhoods => just take top 40
         neighbourhood = fct_reorder(neighbourhood, price)) %>% 
  ggplot(aes(exp(price), neighbourhood)) + 
  geom_boxplot() + 
  scale_x_log10()


train %>% 
  mutate(room_type = fct_reorder(room_type, price)) %>% 
  ggplot(aes(exp(price), room_type)) +
  geom_boxplot() +
  scale_x_log10()

train %>% 
  sample_n(3000) %>% 
  ggplot(aes(minimum_nights, price)) + 
  geom_point() +
  scale_x_log10() + 
  geom_smooth(method = "loess") # not really a trend visible...

train %>% 
  ggplot(aes(number_of_reviews, price)) +
  geom_point() + 
  scale_x_log10() +
  geom_smooth(method = "lm") # flat...

train %>% 
  ggplot(aes(reviews_per_month, price)) +
  geom_point() + 
  scale_x_log10() +
  geom_smooth(method = "lm") # still flat...


train %>% 
  ggplot(aes(calculated_host_listings_count, price)) +
  geom_point() +
  scale_x_log10() +
  geom_smooth(method = "lm") # a tiny positive trend


train %>% 
  # filter(availability_365 > 0) %>% 
  ggplot(aes(availability_365, price)) +
  geom_point() +
  scale_x_log10() +
  geom_smooth(method = "lm") # a tiny positive trend
```


Make a map!
```{r}
library(ggthemes)


train %>% 
  ggplot(aes(longitude, latitude, color = neighbourhood_group)) + 
  geom_point(size = 0.75) + 
  coord_fixed()


train %>% 
  ggplot(aes(longitude, latitude, color = exp(price) - 1)) +
  scale_color_gradient2(low = "blue", high = "red",
                        midpoint = 2,
                        trans = "log10") +
  geom_point(size = 1)


# too many points?
train %>% 
  group_by(latitude = round(latitude, 2),
           longitude = round(longitude, 2)) %>% 
  ggplot(aes(longitude, latitude, color = exp(price) - 1)) +
  scale_color_gradient2(low = "blue", high = "red",
                        midpoint = 2,
                        trans = "log10") +
  geom_point(size = 1) +
  theme_map()
```

get the shapefile of NYC with ggmap!
```{r}
library(ggmap)

bbox <- c(left = -74.24285, bottom =  40.50641, right = -73.71690, top = 40.91306)

### where the numbers come from
# max(train$longitude)
# min(train$longitude)
# max(train$latitude)
# min(train$latitude)

nyc_map <- get_stamenmap(bbox, zoom = 11)
ggmap(nyc_map)
```

Map it!
```{r}
  ggmap(nyc_map) +
  geom_point(data = train,
             aes(longitude, latitude, color = exp(price) - 1),
             size = 0.5) + 
  scale_color_gradient2(low = "blue", mid = "orange", high = "red",
                        midpoint = 2.5,
                        trans = "log10") +
  theme_map()
```

Aggregate for a better visualization
```{r}
aggregated_long_lat <- train %>% 
  group_by(latitude = round(latitude, 2),
           longitude = round(longitude, 2)) %>% 
  summarize(price = mean(price),
            n = n()) %>% 
  filter(n >= 5)

ggmap(nyc_map) +
  geom_point(data = aggregated_long_lat,
             aes(longitude, latitude,
                 color = exp(price) - 1,
                 size = n)) + 
  scale_color_gradient2(low = "blue", mid = "orange", high = "red",
                        midpoint = 2,
                        trans = "log10",
                        labels = dollar) +
  scale_size_continuous(range = c(4, 8)) +
  theme_map() + 
  labs(color = "Price",
       size = "Number of listings") # use Plot Zoom
```

```{r}
train %>% 
  ggplot(aes(last_review, price)) +
  geom_point() +
  geom_smooth(method = "lm")
```

```{r}
train %>% 
  mutate(host_id = factor(host_id),
         host_id = fct_lump(host_id, 50),
         host_id = fct_reorder(host_id, price)) %>%
  ggplot(aes(price, host_id)) +
  geom_boxplot()
  

```


Text analysis
```{r}
library(tidytext)

train %>% 
  unnest_tokens(word, name) %>% 
  count(word, sort = TRUE)

train %>% 
  unnest_tokens(word, name) %>% 
  group_by(word) %>% 
  summarize_prices() %>% 
  head(50) %>% 
  mutate(word = fct_reorder(word, avg_price)) %>% 
  ggplot(aes(avg_price, word, size = n)) +
  geom_point()
```



Start modelling 

Jump into xgboost! # 28:00

```{r}
library(xgboost)

# model set up

mset <- metric_set(rmse)

grid_control <- control_grid(save_pred = TRUE,
                             save_workflow = TRUE,
                             extract = extract_model)
set.seed(2021)
train_fold5 <- train %>% 
  vfold_cv(5)
```


```{r}
# prep function
prep_juice <- function(d) juice(prep(d))


xg_rec <- recipe(price ~ minimum_nights + room_type + number_of_reviews,
       data = train) %>% 
  # step_log(all_numeric_predictors(), offset = 1) %>% 
  step_dummy(all_nominal_predictors())

xg_mod <- boost_tree("regression",
                     mtry = tune(),
                     trees = tune(),
                     learn_rate = 0.01) %>% 
  set_engine("xgboost")

xg_wf <- workflow() %>% 
  add_recipe(xg_rec) %>% 
  add_model(xg_mod)

xg_tune <- xg_wf %>% 
  tune_grid(train_fold5,
            metrics = mset,
            grid = crossing(mtry = c(2, 3), trees = seq(50, 1000, 50)))

autoplot(xg_tune)

xg_tune %>% 
  collect_metrics() %>% 
  arrange(mean)

# 0.535 with minimum version
```

```{r}
xg_rec <- recipe(price ~ minimum_nights + room_type + number_of_reviews +
                   latitude + longitude + neighbourhood_group,
       data = train) %>% 
  # step_log(all_numeric_predictors(), offset = 1) %>% 
  step_dummy(all_nominal_predictors())

xg_mod <- boost_tree("regression",
                     mtry = tune(),
                     trees = tune(),
                     learn_rate = 0.01) %>% 
  set_engine("xgboost")

xg_wf <- workflow() %>% 
  add_recipe(xg_rec) %>% 
  add_model(xg_mod)

xg_tune <- xg_wf %>% 
  tune_grid(train_fold5,
            metrics = mset,
            grid = crossing(mtry = c(2, 4, 6), trees = seq(50, 1000, 50)))

autoplot(xg_tune)

xg_tune %>% 
  collect_metrics() %>% 
  arrange(mean)

# 0.468 once we add latitude, longitude and neighbourhood_group
```

```{r}
xg_rec <- recipe(price ~ minimum_nights + room_type + number_of_reviews +
                   latitude + longitude + neighbourhood_group + reviews_per_month +
                   calculated_host_listings_count + availability_365,
       data = train) %>% 
  # step_log(all_numeric_predictors(), offset = 1) %>% 
  step_dummy(all_nominal_predictors())

xg_mod <- boost_tree("regression",
                     mtry = tune(),
                     trees = tune(),
                     learn_rate = 0.01) %>% 
  set_engine("xgboost")

xg_wf <- workflow() %>% 
  add_recipe(xg_rec) %>% 
  add_model(xg_mod)

xg_tune <- xg_wf %>% 
  tune_grid(train_fold5,
            metrics = mset,
            grid = crossing(mtry = c(2, 4, 6), trees = seq(50, 800, 50))) # make modelling a bit faster...

autoplot(xg_tune)

xg_tune %>% 
  collect_metrics() %>% 
  arrange(mean)

# 0.444 once we add numeric variables like reviews per month
```

```{r}
xg_rec <- recipe(price ~ minimum_nights + room_type + number_of_reviews +
                   latitude + longitude + neighbourhood_group + reviews_per_month +
                   calculated_host_listings_count + availability_365 + last_review,
       data = train) %>% 
  step_mutate(last_review = coalesce(as.integer(Sys.Date() - last_review), 0)) %>% 
  step_dummy(all_nominal_predictors())

xg_mod <- boost_tree("regression",
                     mtry = tune(),
                     trees = tune(),
                     learn_rate = 0.01) %>% 
  set_engine("xgboost")

xg_wf <- workflow() %>% 
  add_recipe(xg_rec) %>% 
  add_model(xg_mod)

xg_tune <- xg_wf %>% 
  tune_grid(train_fold5,
            metrics = mset,
            grid = crossing(mtry = c(3, 5, 7), trees = seq(250, 800, 25)))

autoplot(xg_tune)

xg_tune %>% 
  collect_metrics() %>% 
  arrange(mean)
```

Finalize version without categorical variables:
```{r}
xg_fit <- xg_wf %>% 
  finalize_workflow(select_best(xg_tune)) %>% 
  fit(train)
  
xg_fit %>% 
  augment(test) %>% 
  rmse(price, .pred)

importances <- xgboost::xgb.importance(mode = xg_fit$fit$fit$fit)

importances %>% 
  mutate(Feature = fct_reorder(Feature, Gain)) %>% 
  ggplot(aes(Gain, Feature)) + 
  geom_col()

# what are the most important characteristics of an Airbnb in terms of price?
```

Some more modifications
```{r}
xg_rec <- recipe(price ~ minimum_nights + room_type + number_of_reviews +
                   latitude + longitude + neighbourhood_group + reviews_per_month +
                   calculated_host_listings_count + availability_365 + last_review,
       data = train) %>% 
  step_mutate(is_manhattan = neighbourhood_group == "Manhattan") %>% 
  step_rm(neighbourhood_group) %>% 
  step_mutate(last_review = coalesce(as.integer(Sys.Date() - last_review), 0)) %>% 
  step_dummy(all_nominal_predictors())

xg_mod <- boost_tree("regression",
                     mtry = tune(),
                     trees = tune(),
                     learn_rate = 0.01) %>% 
  set_engine("xgboost")

xg_wf <- workflow() %>% 
  add_recipe(xg_rec) %>% 
  add_model(xg_mod)

xg_tune <- xg_wf %>% 
  tune_grid(train_fold5,
            metrics = mset,
            grid = crossing(mtry = c(4, 5, 6, 7), trees = seq(250, 1000, 25)))

autoplot(xg_tune)

xg_tune %>% 
  collect_metrics() %>% 
  arrange(mean)
```



# 59:00


