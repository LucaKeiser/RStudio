---
title: "Wine Ratings"
author: "Luca"
date: "17/12/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

load packages

```{r}
library(tidyverse)
library(tidytuesdayR)
library(scales)

theme_set(theme_light())

# does matter in combination with the broom-package!
# otherwise the augment()-function throws an error!
# options(na.action = "na.exclude")

# Error: Assigned data `predict(x, na.action = na.pass, ...) %>% unname()` must be compatible with existing data.
# x Existing data has 120975 rows.
# x Assigned data has 115096 rows.
# i Only vectors of size 1 are recycled.
```

Further Details:
When the modeling was performed with na.action = "na.omit" (as is the typical default), rows with NA in the initial data are omitted entirely from the augmented data frame. When the modeling was performed with na.action = "na.exclude", one should provide the original data as a second argument, at which point the augmented data will contain those rows (typically with NAs in place of the new columns). If the original data is not provided to augment() and na.action = "na.exclude", a warning is raised and the incomplete rows are dropped.


## Get the data

```{r}
wine_ratings <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-05-28/winemag-data-130k-v2.csv")

wine_ratings

# view(wine_ratings)
```


### Clean up

```{r}
wine_ratings_clean <- wine_ratings %>% 
  select(-`...1`) %>% 
  # pull out the year with a regular expression!
  
  # 1. attempt:
  #extract(title, "year", "(\\d\\d\\d\\d)", 
  
  # 2. attempt (fist digits has to be 1 or 2; second digit has to be 9 or 0):
  # extract(title, "year", "([12][90]\\d\\d)",
  
  # 3. attempt (just take the years > 2000)
  extract(title, "year", "(20\\d\\d)", 
         convert = TRUE,
         remove = FALSE)  %>% 
  mutate(year = ifelse(year < 1900, NA, year)) %>%
  filter(!is.na(price))
```


## Take a Look at the Distributions first

```{r}
wine_ratings_clean %>% 
  count(country, sort = TRUE)

wine_ratings_clean %>% 
  count(designation, sort = TRUE)

wine_ratings_clean %>% 
  count(country, region_1, sort = TRUE)

wine_ratings_clean %>% 
  count(taster_name, sort = TRUE)

wine_ratings_clean %>% 
  count(variety, sort = TRUE)

wine_ratings_clean %>% 
  filter(!is.na(designation)) %>% 
  count(designation, variety, sort = TRUE)


# some data error => we need to fix the regular expression!
wine_ratings_clean %>% 
  ggplot(aes(year)) + 
  geom_histogram()


wine_ratings_clean %>% 
  ggplot(aes(points)) +
  geom_histogram(binwidth = 1)

# if we want to predict the price we must take the log(price)!
wine_ratings_clean %>% 
  ggplot(aes(price)) +
  geom_histogram() +
  scale_x_log10()
```



############################### Linear Model ###############################

## NOTE: if we create a model, the NAs are automatically dropped!
## This will be important if we try to visualize the model with the
## broom-package!

1) Price
```{r}
## log(price)
ggplot(wine_ratings_clean, aes(price, points))+ 
  geom_point(alpha = 0.1) +
  geom_smooth(method = "lm") +
  scale_x_log10()


summary(lm(points ~ log2(price), data = wine_ratings_clean))
# every time the price doubles, the expected numer of points goes up by 2!
# clear linear trend

```


2) Country

```{r}

# box plots
# NOTE: this does not (!) control for price! Our linear model above does (c.p.!)!
wine_ratings_clean %>% 
  
  # country has to many levels => fct_lump!
  # set US as reference category => compared to the US!
  # NOTE: the base-level does not have any effect on the predictions just changes
  # to which country the numbers are relative to!
  # what is the most reasonable reference category?
  mutate(country = fct_lump(country, 7),
         country = fct_relevel(country, "US"),
         country = fct_reorder(country, points)) %>% 
  
  ggplot(aes(country, points)) +
    geom_boxplot()


# are these differences significant or just due to change?
# => include coutnry in the model!
wine_ratings_clean %>% 
  mutate(country = fct_relevel(fct_lump(country, 7), "US")) %>% 
  lm(points ~ log2(price) + country, data = .) %>% 
  summary()

# all p-values are significant
```



3) Year

```{r}
wine_ratings_clean %>% 
  ggplot(aes(year, points, group = year)) +
  geom_boxplot()

# OR
wine_ratings_clean %>% 
  group_by(year) %>% 
  summarise(points = mean(points)) %>% 
  ggplot(aes(year, points)) +
  geom_line()


wine_ratings_clean %>% 
  group_by(year) %>% 
  count()
# 2017 just ha 11 observations => could be noise!


# include year as a predictor (compare R-squared-values!)
wine_ratings_clean %>% 
  mutate(country = fct_relevel(fct_lump(country, 7), "US")) %>% 
  lm(points ~ log2(price) + country + year, data = .) %>% 
  summary()

# all p-values are significant
```


4) Taster Name

```{r}
wine_ratings_clean %>% 
  mutate(taster_name = fct_lump(taster_name, 10),
         taster_name = fct_reorder(taster_name, points)) %>% 
  ggplot(aes(taster_name, points)) +
  geom_boxplot() +
  coord_flip()


wine_ratings_clean %>% 
  replace_na(list(taster_name = "Missing", country = "Missing")) %>% 
  mutate(country = fct_relevel(fct_lump(country, 7), "US"),
         taster_name = fct_relevel(fct_lump(taster_name, 6), "Missing")) %>% 
  lm(points ~ log2(price) + country + year + taster_name, data = .)


```


Broom-Package to Visualize the model

```{r}
# we have a lot of factors => plot them in a good way
# use broom => converts statistical objects into tidy tibbles!
# coefficient-plot!
library(broom)



############################# SIDENOTE ############################# 

# lm => removes NAs automatically!
# original
wine_ratings_clean %>% 
  nrow()

# model-setting
wine_ratings_clean %>% 
  replace_na(list(taster_name = "Missing")) %>% 
  select(points, price, country, year, taster_name) %>% 
  drop_na() %>% 
  nrow()

# difference: 5879 cases

# so we first need to take care of the NAs!
# here we just drop them...

# create separate tibble
wine_ratings_clean_no_NAs <- wine_ratings_clean %>% 
  replace_na(list(taster_name = "Missing")) %>% 
  select(points, price, country, year, taster_name) %>% 
  drop_na()

wine_ratings_clean_no_NAs


# create the model again and store it as object...
model <- wine_ratings_clean_no_NAs %>% 
  replace_na(list(taster_name = "Missing", country = "Missing")) %>% 
  mutate(country = fct_relevel(fct_lump(country, 7), "US"),
         taster_name = fct_relevel(fct_lump(taster_name, 6), "Missing")) %>% 
  lm(points ~ log2(price) + country + year + taster_name, data = .) 

####################################################################



model %>% 

  # use the broom-package
  # include the confidence-interval
  broom::tidy(conf.int = TRUE,
              conf.level = 0.95) %>% 
  
  # remove the intercept
  filter(term != "(Intercept)") %>% 
  # cleaning the names
  mutate(term = str_replace(term, "country", "Country: "),
         term = str_replace(term, "taster_name", "Taster: "),
         term = str_replace(term, "year", "Year"),
         term = fct_reorder(term, estimate)) %>% 
  
  ggplot(aes(estimate, term)) +
  geom_point() +
  geom_errorbarh(aes(xmin = conf.low, xmax = conf.high))

# price and country = Spain have an high positive impact on the points
# if Michael Schnacher rates the wine => negative impact on the points
# etc.


# visualize the R^2
# add the predictions with broom::augment()
model %>%   
  broom::augment(data = wine_ratings_clean_no_NAs) %>% 
  
  # predicted points and actual points
  ggplot(aes(.fitted, points)) +
  geom_point(alpha = 0.1)

# the model explains some of the variance...


# wich predictor has the highest explanatory power concerning the variance?
stats::anova(model) %>% 
  broom::tidy() %>% 
  mutate(proportion = sumsq / sum(sumsq)) %>% 
  arrange(desc(proportion))
# most of the variance is still not explained (residuals...)
# price explains a lot of the variance!

```


